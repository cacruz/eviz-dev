# Chapter 3: Metadata Generator (metadump)

Welcome back! In [Chapter 1: Configuration System](01_configuration_system_.md), we learned that eViz uses configuration files to get its instructions. Then, in [Chapter 2: Autoviz Application Core](02_autoviz_application_core_.md), we saw how the main `autoviz.py` script acts as the engine, reading those instructions (via the configuration) and orchestrating the process of making plots.

Now, imagine you have a new data file, maybe from a new model run or a different dataset. To use it with eViz, you'd need to create or update the configuration files (`app.yaml` and potentially `specs.yaml`) to tell eViz things like:

*   Where is the file located?
*   What variables are inside?
*   What are the dimensions and units of those variables?
*   Which variables do you want to plot?
*   What are the recommended plot types (like maps, cross-sections, time series)?

Creating these YAML files manually, especially for a file with dozens or hundreds of variables, can be time-consuming and error-prone!

This is where the **Metadata Generator**, also known as **metadump**, comes in.

## What is metadump?

`metadump` is a separate, standalone utility script (`metadump.py`) within the eViz project. Its purpose is to make your life easier by automatically analyzing data files, most commonly NetCDF files, and generating the initial basic configuration and metadata files for you.

Think of `metadump` as a helpful assistant. You point it to a data file, and it peeks inside, figures out what's there (variables, dimensions, attributes), and then writes down those details in formats that eViz can understand â€“ specifically, basic YAML `app` and `specs` files, or even a detailed JSON metadata file.

## Your Third Task: Generating Config Files for a New Data File

Let's say you have a new NetCDF file named `new_model_output.nc`. You want to quickly get started visualizing some variables from it with eViz. Instead of writing the YAML files from scratch, you can use `metadump`.

How do you do this? You run the `metadump.py` script from your terminal.

```bash
python metadump.py /path/to/your/new_model_output.nc
```

That's the simplest way!

By default, if you just provide the file path, `metadump` will analyze the file and *print* a list of variables it thinks are "plottable" (usually variables with spatial or temporal dimensions). This is a quick way to inspect the file.

To actually generate the configuration files that eViz uses, you add command-line arguments:

```bash
python metadump.py /path/to/your/new_model_output.nc --app my_new_app.yaml --specs my_new_specs.yaml
```

This command tells `metadump` to:
1.  Analyze `/path/to/your/new_model_output.nc`.
2.  Generate a basic application configuration and save it to `my_new_app.yaml`.
3.  Generate a basic specifications file (with details about variables) and save it to `my_new_specs.yaml`.

Now you have two YAML files (`my_new_app.yaml` and `my_new_specs.yaml`) that you can potentially use or modify slightly and pass to the main `autoviz.py` script (as discussed in [Chapter 2: Autoviz Application Core](02_autoviz_application_core_.md)).

You can also generate a comprehensive JSON file containing detailed metadata about the file's contents:

```bash
python metadump.py /path/to/your/new_model_output.nc --json my_new_data_metadata.json
```

This creates a `my_new_data_metadata.json` file listing global attributes and details for each variable (dimensions, data type, attributes). This is useful for documentation or other tools, but not typically used directly by the core eViz plotting process.

`metadump` also has options to include only specific variables (`--vars var1 var2`) or ignore certain variables (`--ignore VarNamePart`) when generating YAML, and it can handle comparing two files. You can see all options using `python metadump.py --help`.

## What Do the Generated Files Look Like?

Let's look at simplified examples of the YAML files `metadump` might generate for `new_model_output.nc`.

**`my_new_app.yaml` (Simplified Example):**

```yaml
# Generated by metadump.py

inputs:
  - name: /path/to/your/new_model_output.nc
    # You might add location here later if needed
    to_plot:
      # metadump lists suggested plot types for likely plottable vars
      Temperature: xy,xt # Example: suggests map (xy) and time series (xt)
      SoilMoisture: xy
      Rainfall: xy,xt
      # ... and so on for other plottable variables ...

outputs:
  print_to_file: yes     # Default: save plots to file
  output_dir: null       # Default: uses current directory or a default
  print_format: png      # Default: PNG images
  print_basic_stats: True
  make_pdf: False

system_opts:
  use_mp_pool: False     # Default: do not use multiprocessing
  archive_web_results: True
```

This `app.yaml` file contains the basic structure we saw in [Chapter 1: Configuration System](01_configuration_system_.md): an `inputs` section pointing to your file, an `outputs` section for saving plots, and a `system_opts` section for general settings. The `to_plot` section inside `inputs` is populated by `metadump` with the variables it identified as plottable and suggests plot types based on their dimensions.

**`my_new_specs.yaml` (Simplified Example):**

```yaml
# Generated by metadump.py

Temperature:
  units: K              # Unit from file attribute
  name: Surface Air Temperature # Long name from file attribute
  xtplot:               # Configuration suggested for time series plot
    time_lev: all
    grid: yes
  xyplot:               # Configuration suggested for map plot
    levels:             # Default contour levels (often needs manual tuning)
      0: []
      # ... metadump might add more levels based on data range ...

SoilMoisture:
  units: kg/m^2
  name: Soil Moisture Content
  xyplot: {}            # Basic configuration for map plot

Rainfall:
  units: mm/day
  name: Precipitation Rate
  xtplot:
    time_lev: all
    grid: yes
  xyplot: {}

# ... and so on for other plottable variables ...
```

The `specs.yaml` file generated by `metadump` focuses on individual variables. For each variable identified as plottable, it adds basic metadata like `units` and `name` (read directly from the NetCDF file's attributes if available). It also suggests default configurations for different plot types (`xyplot`, `xtplot`, `yzplot`) based on the variable's dimensions. Note that default contour `levels` might be basic (like just `0: []`) and you'd likely need to edit this file to set meaningful plot aesthetics later.

These generated files give you a solid starting point, saving you the effort of typing out all the variable names and basic file paths from scratch.

## How metadump Works Inside

Let's take a peek under the hood of `metadump.py`. It's a relatively simple script focused on a single task: inspecting a file and generating output.

Here's a simplified sequence:

```{mermaid}
sequenceDiagram
    participant User
    participant CLI as Command Line
    participant MetadumpScript as metadump.py Script
    participant Extractor as MetadataExtractor
    participant NetCDFFile as Your Data File (.nc)
    participant OutputFiles as Generated YAML/JSON Files

    User->>CLI: python metadump.py file.nc --app app.yaml --specs specs.yaml
    CLI->>MetadumpScript: Run with arguments
    MetadumpScript->>Extractor: Create MetadataExtractor(config from args)
    Extractor->>NetCDFFile: Open & read dataset structure (xarray)
    NetCDFFile-->>Extractor: Provides variable names, dims, attrs
    Extractor->>Extractor: Analyze variables, determine plottable types
    Extractor->>Extractor: Generate dict for app.yaml
    Extractor->>Extractor: Generate dict for specs.yaml
    Extractor->>OutputFiles: Write app.yaml (using PyYAML)
    Extractor->>OutputFiles: Write specs.yaml (using PyYAML)
    Extractor-->>MetadumpScript: Process complete
    MetadumpScript-->>CLI: Script finishes
```

The core logic is handled by the `MetadataExtractor` class.

Let's look at very simplified snippets from `metadump.py`:

First, the `main` function handles command-line arguments and sets up the process:

```python
# --- Simplified metadump.py ---
import argparse
import logging
# ... other imports ...

def main():
    # 1. Parse command-line arguments
    args = parse_command_line() # Gets file paths, output names, etc.
    
    # Basic validation and setup
    if len(args.filepaths) > 2:
        # ... error handling ...
        sys.exit(1)

    try:
        # 2. Create a configuration object from arguments
        config = MetadumpConfig(
            filepath_1=args.filepaths[0],
            filepath_2=args.filepaths[1] if len(args.filepaths) == 2 else None,
            app_output=args.app, # e.g., 'my_new_app.yaml'
            specs_output=args.specs, # e.g., 'my_new_specs.yaml'
            json_output=args.json, # e.g., 'my_new_data_metadata.json'
            ignore_vars=args.ignore,
            vars=args.vars,
            source=args.source # e.g., 'gridded'
        )
        
        # 3. Create the main extractor object and run it
        extractor = MetadataExtractor(config)
        extractor.process() # This is where the work happens!
        
    except Exception as e:
        # ... error handling ...
        sys.exit(1)

# ... (if __name__ == "__main__": main()) ...
```

The `main` function's primary job is to parse the command line and create a `MetadumpConfig` object that holds all the settings. It then passes this config to the `MetadataExtractor` class and calls its `process()` method.

The `MetadataExtractor` class is where the core logic resides:

```python
# --- Simplified eviz/metadump.py (MetadataExtractor class) ---
import xarray as xr # Library to read NetCDF
import yaml # Library to write YAML
import json # Library to write JSON
# ... other imports ...

@dataclass
class MetadumpConfig:
    # ... (as shown above) ...
    pass

class MetadataExtractor:
    def __init__(self, config: MetadumpConfig):
        self.config = config
        # 1. Open the dataset(s) using xarray
        self.dataset = self._open_dataset(config.filepath_1)
        self.dataset_2 = self._open_dataset(config.filepath_2) if config.filepath_2 else None
        # ... setup coordinates ...

    def _open_dataset(self, filepath: Optional[str]) -> Optional[xr.Dataset]:
        """Open an xarray dataset from a file."""
        try:
            # xarray handles reading NetCDF files easily
            return xr.open_dataset(filepath, decode_cf=True)
        except Exception as e:
            # ... log error ...
            raise RuntimeError(f"Could not open dataset: {e}")

    def process(self) -> None:
        """Main processing method to generate all required outputs."""
        if self.config.json_output:
            # 2a. Generate JSON metadata if requested
            self._generate_json_metadata()
            return # Stop here if only JSON is needed

        # 2b. Generate YAML data structures if YAML is requested
        specs_dict = self._generate_specs_dict()
        app_dict = self._generate_app_dict()

        # 3. Write the generated data structures to files
        if self.config.specs_output:
            self._write_specs_yaml(specs_dict)
        if self.config.app_output:
            self._write_app_yaml(app_dict)

        # ... (Handle case where no output file is specified - just print variables) ...

    def _generate_specs_dict(self) -> Dict:
        """Generate the specifications dictionary for YAML output."""
        specs_dict = {}
        # Get list of variables to include based on args (--vars, --ignore)
        plottable_vars = self.get_plottable_vars() 

        for var_name in plottable_vars:
            var = self.dataset[var_name]
            # Process each variable to determine its plot types and attributes
            specs_dict[var_name] = self._process_variable(var_name, var)

        return specs_dict

    def _generate_app_dict(self) -> Dict:
        """Generate the application dictionary for YAML output."""
        # Build the basic app structure
        app_dict = {
            "inputs": [{
                "name": self.config.filepath_1,
                "to_plot": self._get_plot_types() # Determine suggested plot types
            }],
            # ... outputs and system_opts sections ...
        }
        
        # Add comparison config if a second file was provided
        if self.config.filepath_2:
             self._add_comparison_config(app_dict)

        return app_dict

    def _write_specs_yaml(self, specs_dict: Dict) -> None:
        """Write specifications dictionary to YAML file."""
        # Use the yaml library to dump the dictionary to a file
        with open(self.config.specs_output, 'w') as file:
            yaml.dump(specs_dict, file, default_flow_style=False)
            # ... (some string replacements for 'yes') ...

    def _write_app_yaml(self, app_dict: Dict) -> None:
        """Write application dictionary to YAML file."""
         # Use the yaml library to dump the dictionary to a file
        with open(self.config.app_output, 'w') as file:
            yaml.dump(app_dict, file, default_flow_style=False)
            # ... (some string replacements for 'yes') ...

    # ... (Helper methods like _process_variable, _get_plot_types, 
    #      get_plottable_vars, _add_comparison_config, is_plottable, 
    #      has_multiple_time_levels, get_model_dim_name, json_compatible) ...
```

The key steps in `MetadataExtractor` are:
*   **`__init__`**: Opens the NetCDF file(s) using `xarray.open_dataset()`. `xarray` is a powerful library that makes it easy to work with labeled multi-dimensional data, like that found in NetCDF files. It loads the structure of the data (variable names, dimensions, attributes) without necessarily loading all the data values into memory, which is perfect for metadata extraction.
*   **`process()`**: This method orchestrates the generation. It calls internal methods like `_generate_specs_dict()`, `_generate_app_dict()`, and `_generate_json_metadata()` to create Python dictionaries representing the content of the desired output files.
*   **`_generate_specs_dict()` / `_generate_app_dict()`**: These methods loop through the variables in the dataset (`self.dataset.data_vars`), inspect their dimensions and attributes, and build the Python dictionaries that will become the YAML files. They use helper functions like `is_plottable` to guess which variables are suitable for plotting and what plot types make sense.
*   **`_write_specs_yaml()` / `_write_app_yaml()` / `_generate_json_metadata()`**: These methods take the generated dictionaries and use the `yaml` and `json` libraries to write them to the specified output files in the correct format.

Helper functions like `is_plottable` examine a variable's dimensions (`var.dims`) and compare them to known spatial (`xc`, `yc`, `zc`) or temporal (`tc`) dimension names (which are looked up using `get_model_dim_name` based on the `source` type) to determine if it's likely a 2D map (`xy`), a 3D volume cross-section (`yz`), or has multiple time steps (`xt`).

## Connection to the Rest of eViz

The files generated by `metadump` are designed to be direct inputs for the [Configuration System](01_configuration_system_.md) we discussed in Chapter 1. You can then run the [Autoviz Application Core](02_autoviz_application_core_.md), pointing it to the files `metadump` created:

```bash
python autoviz.py -f my_new_app.yaml -f my_new_specs.yaml
```

The `autoviz.py` script will use its `create_config` function (as shown in [Chapter 2](02_autoviz_application_core_.md)) to load both `my_new_app.yaml` and `my_new_specs.yaml` into the `ConfigManager`. The `ConfigManager` will then hold all the information about your new data file and the suggested plot settings, ready for the [Source Models](05_source_models_.md) and [Plotting Components](04_plotting_components_.md) to use.

While `metadump` is a separate tool from the main `autoviz` execution flow, it's an essential part of the eViz ecosystem, significantly speeding up the initial setup process for new datasets.

## Conclusion

In this chapter, we learned about the Metadata Generator (`metadump.py`), a utility script that automates the process of creating basic eViz configuration files (`app.yaml`, `specs.yaml`) and detailed metadata files (`.json`) from NetCDF data files. We saw how to run it from the command line, looked at examples of the files it generates, and took a simplified peek at its internal workings, including how it uses `xarray` to inspect data and `yaml`/`json` to write output.

`metadump` saves you from manually listing variables and basic settings, providing a convenient starting point for visualizing new datasets with eViz. The files it produces feed directly into the [Configuration System](01_configuration_system_.md) used by the [Autoviz Application Core](02_autoviz_application_core_.md).

Now that we know how to generate configurations and how the main engine uses them, let's dive into the next step: the components that are actually responsible for *drawing* the visualizations.

[Next Chapter: Plotting Components](04_plotting_components_.md)

---

Generated by [AI Codebase Knowledge Builder](https://github.com/The-Pocket/Tutorial-Codebase-Knowledge)
